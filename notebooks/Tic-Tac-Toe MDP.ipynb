{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tic-Tac-Toe MDP\n",
    "In this work, I create a MDP representation of the game Tic-Tac-Toe. We generate all possible states using recursion, and assign winning and losing states with rewards +1 and -1, respectively, and 0 for all other states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining State\n",
    "We use the class `Board` as a representation of a Tic-Tac-Toe state. For every state, there are a finite number of possible actions. If it is the agent's turn, they can place a piece on any available 'slot' in the Tic-Tac-Toe grid. Otherwise, their only action is to wait for their opponent to place a move.\n",
    "\n",
    "MDPs use the notion of `state-action probability`, that is, given a state `s` and action `a`, what is the probability you will end up in state `s'`. When it's the agent's turn, there is 100% probability that their action, i.e. place a piece in the available coordinate `(1,1)`, will take them to `s'` (the modified board with their piece in that position).\n",
    "\n",
    "When it's the opponent's turn, the agent's only action is `a = 'wait'`. There is `1/b` probability that the next state `s'` will have the opponent's piece in one of the `b` available coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is the bot, O is the opponent\n",
    "class Board():\n",
    "    def __init__(self, board=None, first_move=True):\n",
    "        self.board = board\n",
    "        if not board:\n",
    "            self.board = [[''] * 3 for _ in range(3)]\n",
    "        self.first_move = first_move\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'X{str(self.board)}' if self.first_move else f'O{str(self.board)}'\n",
    "    def __hash__(self):\n",
    "        return hash(self.__str__())\n",
    "    def __eq__(self, other):\n",
    "        return self.__str__() == other.__str__()\n",
    "    def __ne__(self, other):\n",
    "        return not(self == other)\n",
    "    \n",
    "    # Returns 'X' if X wins, 'O' if O wins, None if no one wins\n",
    "    def game_over(self):\n",
    "        xsum = 0\n",
    "        osum = 0\n",
    "        \n",
    "        def three_in_row(xsum, osum):\n",
    "            if xsum == 3:\n",
    "                return 'X'\n",
    "            elif osum == 3:\n",
    "                return 'O'\n",
    "            else:\n",
    "                return None\n",
    "        \n",
    "        # Check row-wise\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                xsum += (self.board[i][j] == 'X')\n",
    "                osum += (self.board[i][j] == 'O')\n",
    "            if three_in_row(xsum, osum):\n",
    "                return three_in_row(xsum, osum)\n",
    "            else:\n",
    "                xsum, osum = (0, 0)\n",
    "        \n",
    "        # Check col-wise\n",
    "        for j in range(3):\n",
    "            for i in range(3):\n",
    "                xsum += (self.board[i][j] == 'X')\n",
    "                osum += (self.board[i][j] == 'O')\n",
    "            if three_in_row(xsum, osum):\n",
    "                return three_in_row(xsum, osum)\n",
    "            else:\n",
    "                xsum, osum = (0, 0)\n",
    "        \n",
    "        # Check diag left-to-right\n",
    "        for i in range(3):\n",
    "            xsum += (self.board[i][i] == 'X')\n",
    "            osum += (self.board[i][i] == 'O')\n",
    "        if three_in_row(xsum, osum):\n",
    "            return three_in_row(xsum, osum)\n",
    "        else:\n",
    "            xsum, osum = (0, 0)\n",
    "        \n",
    "        # Check diag right-to-left\n",
    "        for i in range(3):\n",
    "            xsum += (self.board[i][2 - i] == 'X')\n",
    "            osum += (self.board[i][2 - i] == 'O')\n",
    "        if three_in_row(xsum, osum):\n",
    "            return three_in_row(xsum, osum)\n",
    "        else:\n",
    "            xsum, osum = (0, 0)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    # Gets count of pieces on the board\n",
    "    def p_count(self, player):\n",
    "        psum = 0\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                psum += (self.board[i][j] == player)\n",
    "        return psum       \n",
    "    def x_count(self):\n",
    "        return self.p_count('X')\n",
    "    def o_count(self):\n",
    "        return self.p_count('O')\n",
    "    \n",
    "    def p_moves(self, player):\n",
    "        moves = {}\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if self.board[i][j] == '':\n",
    "                    new_state = deepcopy(self)\n",
    "                    new_state.board[i][j] = player\n",
    "                    moves[f'{i},{j}'] = new_state\n",
    "        return moves\n",
    "    \n",
    "    def moves(self, opponent=False):\n",
    "        x_cnt = self.x_count()\n",
    "        o_cnt = self.o_count()\n",
    "        #print(f'Opponent Move: {opponent} ; xcnt = {x_cnt} ; o_cnt = {o_cnt}')\n",
    "        #print(self.board)\n",
    "        if self.game_over():\n",
    "            return {}\n",
    "        if not opponent:\n",
    "            if x_cnt > o_cnt:\n",
    "                return {}\n",
    "            elif x_cnt == o_cnt and not self.first_move:\n",
    "                return {}\n",
    "        else:\n",
    "            if o_cnt > x_cnt:\n",
    "                return {}\n",
    "            elif x_cnt == o_cnt and self.first_move:\n",
    "                return {}\n",
    "        \n",
    "        player = 'O' if opponent else 'X'\n",
    "        return self.p_moves(player)\n",
    "    \n",
    "    def actions(self):\n",
    "        actions = list(self.moves().keys())\n",
    "        if not actions and not self.game_over():\n",
    "            actions = ['wait']\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating States and Rewards\n",
    "We must consider all possible states of Tic-Tac-Toe, including both when the agent goes first _and_ the opponent goes first. Using these two 'base' states (empty board), we recursively generate all possible states using the available actions of each board state for both the agent and the opponent. When the board state is considered to be _game over_, we assign the respective reward of that state for the agent.\n",
    "\n",
    "# Training the Agent\n",
    "We iterate over all possible states and use the bellman equation to define the expected reward for each given state. Once converged, we define the policy to take the action which yeilds the highest expected reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.states = []\n",
    "        self.rewards = {}\n",
    "\n",
    "    def reward(self, board):\n",
    "        if board in self.rewards:\n",
    "            return self.rewards[board]\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    # For a given state and action, return pairs of (result-state, probability)\n",
    "    def state_action_prob(self, board, action):\n",
    "        # If action is wait, equal chance opponent makes any available move\n",
    "        if action == 'wait':\n",
    "            moves = board.moves(opponent=True)\n",
    "            return [(state, 1/len(moves)) for state in moves.values()]\n",
    "        # Otherwise, specified action will always occur\n",
    "        else:\n",
    "            moves = board.moves()\n",
    "            return [(moves[action], 1.0)]\n",
    "    \n",
    "    def _generate_action_rewards(self, board, depth):\n",
    "        #time.sleep(1)\n",
    "        self.states.append(board)\n",
    "        \n",
    "        moves = board.moves()\n",
    "        if not moves:\n",
    "            game_over_output = board.game_over()\n",
    "            if game_over_output == 'X':\n",
    "                self.rewards[board] = 1\n",
    "            elif game_over_output == 'O':\n",
    "                self.rewards[board] = -1\n",
    "            else:\n",
    "                moves = board.moves(opponent=True)\n",
    "\n",
    "        for board_t in moves.values():\n",
    "            self._generate_action_rewards(board_t, depth+1)\n",
    "\n",
    "    def generate_action_rewards(self, player='X'):\n",
    "        board_1 = Board(first_move=True)\n",
    "        board_2 = Board(first_move=False)\n",
    "        self._generate_action_rewards(board_1, depth=0)\n",
    "        self._generate_action_rewards(board_2, depth=0)\n",
    "    \n",
    "    def state_values(self, gamma=0.9, epsilon=0.001):\n",
    "        V = {s: 0 for s in self.states}\n",
    "        epoch = 0\n",
    "        \n",
    "        while True:\n",
    "            epoch += 1\n",
    "            V1 = deepcopy(V)\n",
    "            delta = 0\n",
    "            \n",
    "            for s in self.states:\n",
    "                V[s] = self.reward(s) + gamma * max( [sum( [p * V[s_] for (s_, p) in self.state_action_prob(s, a)] ) for a in s.actions()], default=0)\n",
    "                delta = max(delta, V1[s] - V[s])\n",
    "            \n",
    "            print(f'Epoch {epoch}; delta = {delta}')\n",
    "            if delta < epsilon:\n",
    "                return V1\n",
    "    \n",
    "    def policy(self):\n",
    "        V = self.state_values()\n",
    "        P = {}\n",
    "        \n",
    "        def expected_state_value(s, a):\n",
    "            return sum([ p * V[s_] for (s_, p) in self.state_action_prob(s, a) ])\n",
    "        \n",
    "        for s in self.states:\n",
    "            P[s] = max(s.actions(), key=lambda a: expected_state_value(s, a), default=None)\n",
    "        \n",
    "        return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TicTacToe()\n",
    "t.generate_action_rewards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1; delta = 1.0\n",
      "Epoch 2; delta = 0.0005623714285714065\n"
     ]
    }
   ],
   "source": [
    "P = t.policy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing our Tic-Tac-Toe Agent\n",
    "We play a game against the agent, where they have the first move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,0'"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Board(board=[['', '', ''],\n",
    "                 ['', '', ''],\n",
    "                 ['', '', '']], first_move=True)\n",
    "P[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wait'"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Board(board=[['X', '', ''],\n",
    "                 ['',  '', ''],\n",
    "                 ['',  '', '']], first_move=True)\n",
    "P[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,1'"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Board(board=[['X', '',  ''],\n",
    "                 ['',  'O', ''],\n",
    "                 ['',  '',  '']], first_move=True)\n",
    "P[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wait'"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Board(board=[['X', 'X',  ''],\n",
    "                 ['',  'O', ''],\n",
    "                 ['',  '',  '']], first_move=True)\n",
    "P[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2,0'"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Board(board=[['X', 'X', 'O'],\n",
    "                 ['',  'O', ''],\n",
    "                 ['',  '',  '']], first_move=True)\n",
    "P[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wait'"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Board(board=[['X', 'X', 'O'],\n",
    "                 ['',  'O', ''],\n",
    "                 ['X', '',  '']], first_move=True)\n",
    "P[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,2'"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Board(board=[['X', 'X', 'O'],\n",
    "                 ['O', 'O', ''],\n",
    "                 ['X', '',  '']], first_move=True)\n",
    "P[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wait'"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Board(board=[['X', 'X', 'O'],\n",
    "                 ['O', 'O', 'X'],\n",
    "                 ['X', '',  '']], first_move=True)\n",
    "P[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2,2'"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Board(board=[['X', 'X', 'O'],\n",
    "                 ['O', 'O', 'X'],\n",
    "                 ['X', 'O', '']], first_move=True)\n",
    "P[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wait'"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Board(board=[['X', 'X', 'O'],\n",
    "                 ['O', 'O', 'X'],\n",
    "                 ['X', 'O', 'X']], first_move=True)\n",
    "P[b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Cat's game! Our agent is intelligent enough to win or tie every single game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
